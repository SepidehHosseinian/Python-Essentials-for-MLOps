{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ðŸ¤— HuggingFace Datasets\n",
    "\n",
    "HuggingFace provides the ability to interact with datasets dynamically. There is no need to pre-download large models and include them in a repository like this one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,list_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36106\n",
      "['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc', 'afrikaans_ner_corpus', 'ag_news', 'ai2_arc', 'air_dialogue', 'ajgt_twitter_ar', 'allegro_reviews', 'allocine', 'alt', 'amazon_polarity', 'amazon_reviews_multi', 'amazon_us_reviews', 'ambig_qa', 'americas_nli', 'ami', 'amttl', 'anli', 'app_reviews', 'aqua_rat', 'aquamuse', 'ar_cov19', 'ar_res_reviews', 'ar_sarcasm', 'arabic_billion_words', 'arabic_pos_dialect', 'arabic_speech_corpus', 'arcd', 'arsentd_lev', 'art', 'arxiv_dataset', 'ascent_kb', 'aslg_pc12', 'asnq', 'asset', 'assin', 'assin2', 'atomic', 'autshumato', 'banking77', 'bbaw_egyptian', 'bbc_hindi_nli', 'bc2gm_corpus', 'beans', 'best2009', 'bianet', 'bible_para', 'big_patent', 'billsum', 'bing_coronavirus_query_set', 'biomrc', 'biosses', 'blbooks', 'blbooksgenre', 'blended_skill_talk', 'blimp', 'blog_authorship_corpus', 'bn_hate_speech', 'bnl_newspapers', 'bookcorpus', 'bookcorpusopen', 'boolq', 'bprec', 'break_data', 'brwac', 'bsd_ja_en', 'bswac', 'c3', 'c4', 'cail2018', 'caner', 'capes', 'casino', 'catalonia_independence', 'cats_vs_dogs', 'cawac', 'cbt', 'cc100', 'cc_news', 'ccaligned_multilingual', 'cdsc', 'cdt', 'cedr', 'cfq', 'chr_en', 'cifar10', 'cifar100', 'circa', 'civil_comments', 'clickbait_news_bg', 'climate_fever', 'clinc_oos', 'clue', 'cmrc2018', 'cmu_hinglish_dog', 'cnn_dailymail', 'coached_conv_pref', 'coarse_discourse', 'codah', 'code_search_net', 'code_x_glue_cc_clone_detection_big_clone_bench', 'code_x_glue_cc_clone_detection_poj104', 'code_x_glue_cc_cloze_testing_all', 'code_x_glue_cc_cloze_testing_maxmin', 'code_x_glue_cc_code_completion_line', 'code_x_glue_cc_code_completion_token', 'code_x_glue_cc_code_refinement', 'code_x_glue_cc_code_to_code_trans', 'code_x_glue_cc_defect_detection', 'code_x_glue_ct_code_to_text', 'code_x_glue_tc_nl_code_search_adv', 'code_x_glue_tc_text_to_code', 'code_x_glue_tt_text_to_text', 'com_qa', 'common_gen', 'common_language', 'common_voice', 'commonsense_qa', 'competition_math', 'compguesswhat', 'conceptnet5', 'conll2000', 'conll2002', 'conll2003', 'conllpp', 'consumer-finance-complaints', 'conv_ai', 'conv_ai_2', 'conv_ai_3', 'conv_questions', 'coqa', 'cornell_movie_dialog', 'cos_e', 'cosmos_qa', 'counter', 'covid_qa_castorini', 'covid_qa_deepset', 'covid_qa_ucsd', 'covid_tweets_japanese', 'covost2', 'cppe-5', 'craigslist_bargains', 'crawl_domain', 'crd3', 'crime_and_punish', 'crows_pairs', 'cryptonite', 'cs_restaurants', 'cuad', 'curiosity_dialogs', 'daily_dialog', 'dane', 'danish_political_comments', 'dart', 'datacommons_factcheck', 'dbpedia_14', 'dbrd', 'deal_or_no_dialog', 'definite_pronoun_resolution', 'dengue_filipino', 'dialog_re', 'diplomacy_detection', 'disaster_response_messages', 'discofuse', 'discovery', 'disfl_qa', 'doc2dial', 'docred', 'doqa', 'dream', 'drop', 'duorc', 'dutch_social', 'dyk', 'e2e_nlg', 'e2e_nlg_cleaned', 'ecb', 'ecthr_cases', 'eduge', 'ehealth_kd', 'eitb_parcc', 'electricity_load_diagrams', 'eli5', 'eli5_category', 'emea', 'emo', 'emotone_ar', 'empathetic_dialogues', 'enriched_web_nlg', 'eraser_multi_rc', 'esnli', 'eth_py150_open', 'ethos', 'eu_regulatory_ir', 'eurlex', 'euronews', 'europa_eac_tm', 'europa_ecdc_tm', 'europarl_bilingual', 'event2Mind', 'evidence_infer_treatment', 'exams', 'factckbr', 'fake_news_english', 'fake_news_filipino', 'farsi_news', 'fashion_mnist', 'fever', 'few_rel', 'financial_phrasebank', 'finer', 'flores', 'flue', 'food101', 'fquad', 'freebase_qa', 'gap', 'gem', 'generated_reviews_enth', 'generics_kb', 'german_legal_entity_recognition', 'germaner', 'germeval_14', 'giga_fren', 'gigaword', 'glucose', 'glue', 'gnad10', 'go_emotions', 'gooaq', 'google_wellformed_query', 'grail_qa', 'great_code', 'greek_legal_code', 'guardian_authorship', 'gutenberg_time', 'hans', 'hansards', 'hard', 'harem', 'has_part', 'hate_offensive', 'hate_speech18', 'hate_speech_filipino', 'hate_speech_offensive', 'hate_speech_pl', 'hate_speech_portuguese', 'hatexplain', 'hausa_voa_ner', 'hausa_voa_topics', 'hda_nli_hindi', 'head_qa', 'health_fact', 'hebrew_projectbenyehuda', 'hebrew_sentiment', 'hebrew_this_world', 'hellaswag', 'hind_encorp', 'hindi_discourse', 'hippocorpus', 'hkcancor', 'hlgd', 'hope_edi', 'hotpot_qa', 'hover', 'hrenwac_para', 'hrwac', 'humicroedit', 'hybrid_qa', 'hyperpartisan_news_detection', 'iapp_wiki_qa_squad', 'id_clickbait', 'id_liputan6', 'id_nergrit_corpus', 'id_newspapers_2018', 'id_panl_bppt', 'id_puisi', 'igbo_english_machine_translation', 'igbo_monolingual', 'igbo_ner', 'ilist', 'imdb', 'imdb_urdu_reviews', 'imppres', 'indic_glue', 'indonli', 'inquisitive_qg', 'interpress_news_category_tr', 'interpress_news_category_tr_lite', 'irc_disentangle', 'isixhosa_ner_corpus', 'isizulu_ner_corpus', 'iwslt2017', 'jeopardy', 'jfleg', 'jigsaw_toxicity_pred', 'jigsaw_unintended_bias', 'jnlpba', 'journalists_questions', 'kan_hope', 'kannada_news', 'kd_conv', 'kde4', 'kelm', 'kilt_tasks', 'kilt_wikipedia', 'kinnews_kirnews', 'klue', 'kor_3i4k', 'kor_hate', 'kor_ner', 'kor_nli', 'kor_nlu', 'kor_qpair', 'kor_sae', 'kor_sarcasm', 'labr', 'lama', 'lambada', 'large_spanish_corpus', 'laroseda', 'lc_quad', 'lener_br', 'lex_glue', 'liar', 'librispeech_asr', 'librispeech_lm', 'limit', 'lince', 'linnaeus', 'liveqa', 'lj_speech', 'lm1b', 'lst20', 'm_lama', 'mac_morpho', 'makhzan', 'masakhaner', 'math_dataset', 'math_qa', 'matinf', 'mbpp', 'mc4', 'mc_taco', 'md_gender_bias', 'mdd', 'med_hop', 'medal', 'medical_dialog', 'medical_questions_pairs', 'menyo20k_mt', 'meta_woz', 'metooma', 'metrec', 'miam', 'mkb', 'mkqa', 'mlqa', 'mlsum', 'mnist', 'mocha', 'moroco', 'movie_rationales', 'mrqa', 'ms_marco', 'ms_terms', 'msr_genomics_kbcomp', 'msr_sqa', 'msr_text_compression', 'msr_zhen_translation_parity', 'msra_ner', 'mt_eng_vietnamese', 'muchocine', 'multi_booked', 'multi_eurlex', 'multi_news', 'multi_nli', 'multi_nli_mismatch', 'multi_para_crawl', 'multi_re_qa', 'multi_woz_v22', 'multi_x_science_sum', 'multidoc2dial', 'multilingual_librispeech', 'mutual_friends', 'mwsc', 'myanmar_news', 'narrativeqa', 'narrativeqa_manual', 'natural_questions', 'ncbi_disease', 'nchlt', 'ncslgr', 'nell', 'neural_code_search', 'news_commentary', 'newsgroup', 'newsph', 'newsph_nli', 'newspop', 'newsqa', 'newsroom', 'nkjp-ner', 'nli_tr', 'nlu_evaluation_data', 'norec', 'norne', 'norwegian_ner', 'nq_open', 'nsmc', 'numer_sense', 'numeric_fused_head', 'oclar', 'offcombr', 'offenseval2020_tr', 'offenseval_dravidian', 'ofis_publik', 'ohsumed', 'ollie', 'omp', 'onestop_english', 'onestop_qa', 'open_subtitles', 'openai_humaneval', 'openbookqa', 'openslr', 'openwebtext', 'opinosis', 'opus100', 'opus_books', 'opus_dgt', 'opus_dogc', 'opus_elhuyar', 'opus_euconst', 'opus_finlex', 'opus_fiskmo', 'opus_gnome', 'opus_infopankki', 'opus_memat', 'opus_montenegrinsubs', 'opus_openoffice', 'opus_paracrawl', 'opus_rf', 'opus_tedtalks', 'opus_ubuntu', 'opus_wikipedia', 'opus_xhosanavy', 'orange_sum', 'oscar', 'para_crawl', 'para_pat', 'parsinlu_reading_comprehension', 'pass', 'paws-x', 'paws', 'pec', 'peoples_daily_ner', 'per_sent', 'persian_ner', 'pg19', 'php', 'pib', 'piqa', 'pn_summary', 'poem_sentiment', 'polemo2', 'poleval2019_cyberbullying', 'poleval2019_mt', 'polsum', 'polyglot_ner', 'prachathai67k', 'pragmeval', 'proto_qa', 'psc', 'ptb_text_only', 'pubmed', 'pubmed_qa', 'py_ast', 'qa4mre', 'qa_srl', 'qa_zre', 'qangaroo', 'qanta', 'qasc', 'qed', 'qed_amara', 'quac', 'quail', 'quarel', 'quartz', 'quora', 'quoref', 'race', 're_dial', 'reasoning_bg', 'recipe_nlg', 'reclor', 'red_caps', 'reddit', 'reddit_tifu', 'refresd', 'reuters21578', 'riddle_sense', 'ro_sent', 'ro_sts', 'ro_sts_parallel', 'roman_urdu', 'ronec', 'ropes', 'rotten_tomatoes', 'samsum', 'sanskrit_classic', 'saudinewsnet', 'sberquad', 'scan', 'scb_mt_enth_2020', 'scene_parse_150', 'schema_guided_dstc8', 'scielo', 'scientific_papers', 'sciq', 'scitail', 'search_qa', 'sede', 'selqa', 'sem_eval_2010_task_8', 'sem_eval_2014_task_1', 'sem_eval_2018_task_1', 'sem_eval_2020_task_11', 'sent_comp', 'senti_lex', 'senti_ws', 'sentiment140', 'sepedi_ner', 'sesotho_ner_corpus', 'setimes', 'setswana_ner_corpus', 'sharc', 'sharc_modified', 'sick', 'silicone', 'simple_questions_v2', 'siswati_ner_corpus', 'smartdata', 'sms_spam', 'snips_built_in_intents', 'snli', 'snow_simplified_japanese_corpus', 'so_stacksample', 'social_bias_frames', 'social_i_qa', 'sofc_materials_articles', 'sogou_news', 'spanish_billion_words', 'spc', 'species_800', 'speech_commands', 'spider', 'squad', 'squad_adversarial', 'squad_es', 'squad_it', 'squad_kor_v1', 'squad_kor_v2', 'squad_v1_pt', 'squad_v2', 'squadshifts', 'srwac', 'sst', 'stereoset', 'story_cloze', 'stsb_mt_sv', 'stsb_multi_mt', 'style_change_detection', 'subjqa', 'super_glue', 'superb', 'svhn', 'swag', 'swahili', 'swahili_news', 'swda', 'swedish_medical_ner', 'swedish_ner_corpus', 'swedish_reviews', 'tab_fact', 'tamilmixsentiment', 'tanzil', 'tapaco', 'tashkeela', 'taskmaster1', 'taskmaster2', 'taskmaster3', 'tatoeba', 'ted_hrlr', 'ted_iwlst2013', 'ted_multi', 'ted_talks_iwslt', 'telugu_books', 'telugu_news', 'tep_en_fa_para', 'text2log', 'thai_toxicity_tweet', 'thainer', 'thaiqa_squad', 'thaisum', 'the_pile_books3', 'the_pile_openwebtext2', 'the_pile_stack_exchange', 'tilde_model', 'time_dial', 'times_of_india_news_headlines', 'timit_asr', 'tiny_shakespeare', 'tlc', 'tmu_gfm_dataset', 'told-br', 'totto', 'trec', 'trivia_qa', 'tsac', 'ttc4900', 'tunizi', 'tuple_ie', 'turk', 'turkic_xwmt', 'turkish_movie_sentiment', 'turkish_ner', 'turkish_product_reviews', 'turkish_shrinked_ner', 'turku_ner_corpus', 'tweet_eval', 'tweet_qa', 'tweets_ar_en_parallel', 'tweets_hate_speech_detection', 'twi_text_c3', 'twi_wordsim353', 'tydiqa', 'ubuntu_dialogs_corpus', 'udhr', 'um005', 'un_ga', 'un_multi', 'un_pc', 'universal_dependencies', 'universal_morphologies', 'urdu_fake_news', 'urdu_sentiment_corpus', 'vctk', 'vivos', 'web_nlg', 'web_of_science', 'web_questions', 'weibo_ner', 'wi_locness', 'wider_face', 'wiki40b', 'wiki_asp', 'wiki_atomic_edits', 'wiki_auto', 'wiki_bio', 'wiki_dpr', 'wiki_hop', 'wiki_lingua', 'wiki_movies', 'wiki_qa', 'wiki_qa_ar', 'wiki_snippets', 'wiki_source', 'wiki_split', 'wiki_summary', 'wikiann', 'wikicorpus', 'wikihow', 'wikipedia', 'wikisql', 'wikitext', 'wikitext_tl39', 'wili_2018', 'wino_bias', 'winograd_wsc', 'winogrande', 'wiqa', 'wisesight1000', 'wisesight_sentiment', 'wmt14', 'wmt15', 'wmt16', 'wmt17', 'wmt18', 'wmt19', 'wmt20_mlqe_task1', 'wmt20_mlqe_task2', 'wmt20_mlqe_task3', 'wmt_t2t', 'wnut_17', 'wongnai_reviews', 'woz_dialogue', 'wrbsc', 'x_stance', 'xcopa', 'xcsr', 'xed_en_fi', 'xglue', 'xnli', 'xor_tydi_qa', 'xquad', 'xquad_r', 'xsum', 'xsum_factuality', 'xtreme', 'yahoo_answers_qa', 'yahoo_answers_topics', 'yelp_polarity', 'yelp_review_full', 'yoruba_bbc_topics', 'yoruba_gv_ner', 'yoruba_text_c3', 'yoruba_wordsim353', 'youtube_caption_corrections', 'zest', 'elkarhizketak', 'wikitablequestions', 'conll2012_ontonotesv5', 'monash_tsf', 'roman_urdu_hate_speech', 'adv_glue', 'metashift', 'gsm8k', 'sbu_captions', 'conceptual_captions', 'conceptual_12m', 'visual_genome', 'imagenet-1k', 'tne', 'textvqa', 'ett', 'medmcqa', 'imagenet_sketch', 'biwi_kinect_head_pose', 'enwik8', 'truthful_qa', 'bigbench', 'quickdraw', 'sst2', 'lccc']\n"
     ]
    }
   ],
   "source": [
    "# Explore available datasets\n",
    "available = list_datasets()\n",
    "print(len(available))\n",
    "print([i for i in available if '/' not in i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.42k/4.42k [00:00<00:00, 2.64MB/s]\n",
      "Downloading metadata: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.94k/1.94k [00:00<00:00, 617kB/s]\n",
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.65k/6.65k [00:00<00:00, 3.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset movie_rationales/default to /home/sepideh/.cache/huggingface/datasets/movie_rationales/default/0.1.0/70ed6b72496c90835e8ee73ebf8d0e49f5ad3aa93f302c8a4b6c886143cfb779...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HF google storage unreachable. Downloading and preparing it from source\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.90M/3.90M [00:26<00:00, 147kB/s] \n",
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset movie_rationales downloaded and prepared to /home/sepideh/.cache/huggingface/datasets/movie_rationales/default/0.1.0/70ed6b72496c90835e8ee73ebf8d0e49f5ad3aa93f302c8a4b6c886143cfb779. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 910.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# load the dataset dynamically by passing the name. \n",
    "movie_rationales = load_dataset(\"movie_rationales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label', 'evidences'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review', 'label', 'evidences'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label', 'evidences'],\n",
       "        num_rows: 199\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The object is a dict-like mapping of actual datasets\n",
    "movie_rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Select the \"train\" dataset and then port it to pandas\n",
    "train = movie_rationales[\"train\"]\n",
    "df = train.to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  1600.000000\n",
       "mean      0.500000\n",
       "std       0.500156\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.500000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>evidences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[mind - fuck movie, the sad part is, downshift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard 's quick movie review damn\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>[it 's pretty much a sunken ship, sutherland i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the characters and acting is nothing spectacu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" quest for camelot \" is warner bros . '\\nfirs...</td>\n",
       "      <td>0</td>\n",
       "      <td>[dead on arrival, the characters stink, subpar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[it is highly derivative and somewhat boring, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  \\\n",
       "0  plot : two teen couples go to a church party ,...      0   \n",
       "1  the happy bastard 's quick movie review damn\\n...      0   \n",
       "2  it is movies like these that make a jaded movi...      0   \n",
       "3  \" quest for camelot \" is warner bros . '\\nfirs...      0   \n",
       "4  synopsis : a mentally unstable man undergoing ...      0   \n",
       "\n",
       "                                           evidences  \n",
       "0  [mind - fuck movie, the sad part is, downshift...  \n",
       "1  [it 's pretty much a sunken ship, sutherland i...  \n",
       "2  [the characters and acting is nothing spectacu...  \n",
       "3  [dead on arrival, the characters stink, subpar...  \n",
       "4  [it is highly derivative and somewhat boring, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
